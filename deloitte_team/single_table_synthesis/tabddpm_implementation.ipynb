{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "comprehensive-logging",
   "metadata": {},
   "source": [
    "<center>\n",
    "  \n",
    "# TABDDPM: Modelling Tabular Data with Diffusion Models\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d7a55",
   "metadata": {},
   "source": [
    "Directly applying diffusion models to general tabular problems can be challenging because data points are typically represented by vectors of heterogeneous features. The inherent heterogeneity of tabular data complicates accurate modeling, as individual features can vary widely in nature; some may be continuous, while others are discrete. In this notebook, we explore **TabDDPM** â€” a diffusion model that can be universally applied to tabular datasets and effectively handles both categorical and numerical features.\n",
    "\n",
    "Our primary focus in this work is synthetic data generation, which is in high demand for many tabular tasks. Firstly, tabular datasets are often limited in size, unlike vision or NLP problems where large amounts of additional data are readily available online. Secondly, properly generated synthetic datasets do not contain actual user data, thus avoiding GDPR-like regulations and allowing for public sharing without compromising anonymity.\n",
    "\n",
    "In the following sections, we will delve deeper into the implementation of this method. The notebook is organized as follows:\n",
    "\n",
    "1. [Imports and Setup]()\n",
    "\n",
    "\n",
    "2. [Default Dataset]()\n",
    "\n",
    "    2.1. [Download Data]()\n",
    "    \n",
    "    2.2. [Process Data]()\n",
    "    \n",
    "    2.3. [Review Data]()\n",
    "    \n",
    "    \n",
    "3. [TabDDPM Algorithm]()\n",
    "    \n",
    "    3.1. [Load Config]()\n",
    "    \n",
    "    3.2. [Make Dataset]()\n",
    "    \n",
    "    3.3. [Instantiate Model]()\n",
    "    \n",
    "    3.4. [Train Model]()\n",
    "    \n",
    "    3.5. [Load Pretrained Model]()\n",
    "    \n",
    "    3.6. [Sample Data]()\n",
    "    \n",
    "    3.7. [Review Synthetic Data]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a5190",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16c75e8",
   "metadata": {},
   "source": [
    "In this section, we import all necessary libraries and modules required for setting up the environment. This includes basic libraries for such numpy and pandas. We also import essential modules for data loading, model creation, and dataset downloading and processing dataset. We also specify list of possible datasets and their download URL in `NAME_URL_DICT_UCI` where you can use each of these datasets for the rest of this notebook. Furthermore based on `DATA_DIR` we specify path to raw and processed data in `RAW_DATA_DIR` and `PROCESSED_DATA_DIR` to further download the data and process it in a desired format.  Here we will focus on `\"adult\"` dataset thus we will specify it in `DATA_NAME`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cooperative-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import os\n",
    "\n",
    "from scripts.download_dataset import download_from_uci\n",
    "from scripts.process_dataset import process_data\n",
    "\n",
    "from src.data import make_dataset\n",
    "from src.baselines.tabddpm.pipeline import TabDDPM\n",
    "\n",
    "from src.util import visualize_default\n",
    "\n",
    "\n",
    "NAME_URL_DICT_UCI = {\n",
    "    \"adult\": \"https://archive.ics.uci.edu/static/public/2/adult.zip\",\n",
    "    \"default\": \"https://archive.ics.uci.edu/static/public/350/default+of+credit+card+clients.zip\",\n",
    "    \"magic\": \"https://archive.ics.uci.edu/static/public/159/magic+gamma+telescope.zip\",\n",
    "    \"shoppers\": \"https://archive.ics.uci.edu/static/public/468/online+shoppers+purchasing+intention+dataset.zip\",\n",
    "    \"beijing\": \"https://archive.ics.uci.edu/static/public/381/beijing+pm2+5+data.zip\",\n",
    "    \"news\": \"https://archive.ics.uci.edu/static/public/332/online+news+popularity.zip\",\n",
    "}\n",
    "\n",
    "# For shared directory you can change it to \"/projects/diffusion_bootcamp/data/tabular\"\n",
    "DATA_DIR = \"data\"\n",
    "RAW_DATA_DIR = f\"{DATA_DIR}/raw_data\"\n",
    "PROCESSED_DATA_DIR = f\"{DATA_DIR}/processed_data\"\n",
    "SYNTH_DATA_DIR = f\"{DATA_DIR}/synthetic_data\"\n",
    "DATA_NAME = \"default\"\n",
    "\n",
    "MODEL_PATH = \"models/tabddpm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc51ac5c",
   "metadata": {},
   "source": [
    "# Default Dataset\n",
    "\n",
    "In this section, we will download the **Default of Credit Card Clients** dataset from the UCI repository and load it into a pandas DataFrame. This dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005. We will use this dataset to demonstrate the TabDDPM method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-utility",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3100d23",
   "metadata": {},
   "source": [
    "We can download the required adult dataset to the specified directory in `RAW_DATA_DIR` using the download_from_uci function. This function takes the dataset name, the download path, and the URL of the data, and retrieves it from the UCI repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adolescent-korea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing dataset default from UCI.\n",
      "Already downloaded.\n"
     ]
    }
   ],
   "source": [
    "download_from_uci(DATA_NAME, RAW_DATA_DIR, NAME_URL_DICT_UCI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-blend",
   "metadata": {},
   "source": [
    "## Process Data\n",
    "\n",
    "Now that we have downloaded the dataset, we need to process it into the desired CSV format using the `process_data` function. To do this, we provide the dataset name, the directory containing the information required for preprocessing, and the original data directory. The `INFO_DIR` contains a JSON file for each dataset, specifying the following:\n",
    "\n",
    "1. task_type: This must be specified and can be binclass (binary classification) or regression, depending on the type of task for each dataset. For the adult dataset, the task type is binclass.\n",
    "2. column_names: This is optional and contains the names of each column.\n",
    "3. num_col_idx: This is necessary to specify the columns with numerical values.\n",
    "4. cat_col_idx: This is necessary to specify the columns with categorical values.\n",
    "5. target_col_idx: This is necessary to specify the column containing the target value for the regression or classification task.\n",
    "6. file_type: This should be set to \"csv\" by default, as we want to preprocess the files as CSV.\n",
    "7. data_path: Optional\n",
    "8. test_path: Optional\n",
    "9. column_info: Optional\n",
    "10. train_num: Optional\n",
    "11. test_num: Optional\n",
    "\n",
    "The `process_data` function divides the raw data into training and test splits, saving them in `PROCESSED_DATA_DIR`. It also saves the processed information of the data as a JSON file in the same directory. Finally, it prints out general information about the training and test data after preprocessing, including:\n",
    "\n",
    "1. Size of the training, validation, and test tables\n",
    "2. Size of the numerical values in the training table\n",
    "3. Size of the categorical values in the training table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "simplified-ending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing and Saving default Successfully!\n",
      "Dataset Name: default\n",
      "Total Size: 30000\n",
      "Train Size: 27000\n",
      "Test Size: 3000\n",
      "Number of Numerical Columns: 14\n",
      "Number of Categorical Columns: 10\n"
     ]
    }
   ],
   "source": [
    "INFO_DIR = \"data_info\"\n",
    "process_data(DATA_NAME, INFO_DIR, DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-cologne",
   "metadata": {},
   "source": [
    "## Review Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad79ab5",
   "metadata": {},
   "source": [
    "After preprocessing, we will review the training dataset. To clarify the meaning of each categorical column value, we used the descriptions provided [here](https://www.kaggle.com/datasets/uciml/default-of-credit-card-clients-dataset). We implemented a `visualize_default` function that takes a DataFrame as input and replaces each category with its respective description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rapid-booth",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>married</td>\n",
       "      <td>24.0</td>\n",
       "      <td>payment delay for three months</td>\n",
       "      <td>payment delay for three months</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>...</td>\n",
       "      <td>18457.0</td>\n",
       "      <td>21381.0</td>\n",
       "      <td>18914.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1646.0</td>\n",
       "      <td>678.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>married</td>\n",
       "      <td>39.0</td>\n",
       "      <td>payment delay for four months</td>\n",
       "      <td>payment delay for three months</td>\n",
       "      <td>payment delay for three months</td>\n",
       "      <td>payment delay for three months</td>\n",
       "      <td>payment delay for three months</td>\n",
       "      <td>...</td>\n",
       "      <td>125357.0</td>\n",
       "      <td>121853.0</td>\n",
       "      <td>124731.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6216.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4552.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230000.0</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>single</td>\n",
       "      <td>23.0</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>...</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>12525.0</td>\n",
       "      <td>12219.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>14019.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>12525.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>female</td>\n",
       "      <td>graduate school</td>\n",
       "      <td>married</td>\n",
       "      <td>35.0</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>male</td>\n",
       "      <td>graduate school</td>\n",
       "      <td>married</td>\n",
       "      <td>39.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2920.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2920.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12140.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>male</td>\n",
       "      <td>high school</td>\n",
       "      <td>others</td>\n",
       "      <td>59.0</td>\n",
       "      <td>payment delay for three months</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>...</td>\n",
       "      <td>18055.0</td>\n",
       "      <td>18755.0</td>\n",
       "      <td>20299.0</td>\n",
       "      <td>1596.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>male</td>\n",
       "      <td>university</td>\n",
       "      <td>single</td>\n",
       "      <td>42.0</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>...</td>\n",
       "      <td>17029.0</td>\n",
       "      <td>10575.0</td>\n",
       "      <td>9478.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130000.0</td>\n",
       "      <td>female</td>\n",
       "      <td>graduate school</td>\n",
       "      <td>single</td>\n",
       "      <td>26.0</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>-884.0</td>\n",
       "      <td>-6332.0</td>\n",
       "      <td>-9333.0</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>6730.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>5448.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>married</td>\n",
       "      <td>40.0</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>...</td>\n",
       "      <td>196467.0</td>\n",
       "      <td>201425.0</td>\n",
       "      <td>-8276.0</td>\n",
       "      <td>7028.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>10013.0</td>\n",
       "      <td>9505.0</td>\n",
       "      <td>175074.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>male</td>\n",
       "      <td>university</td>\n",
       "      <td>married</td>\n",
       "      <td>27.0</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for four months</td>\n",
       "      <td>payment delay for three months</td>\n",
       "      <td>...</td>\n",
       "      <td>18472.0</td>\n",
       "      <td>18037.0</td>\n",
       "      <td>18487.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL     SEX        EDUCATION MARRIAGE   AGE  \\\n",
       "0    20000.0  female       university  married  24.0   \n",
       "1   200000.0  female       university  married  39.0   \n",
       "2   230000.0  female       university   single  23.0   \n",
       "3    50000.0  female  graduate school  married  35.0   \n",
       "4   160000.0    male  graduate school  married  39.0   \n",
       "5    20000.0    male      high school   others  59.0   \n",
       "6    50000.0    male       university   single  42.0   \n",
       "7   130000.0  female  graduate school   single  26.0   \n",
       "8   300000.0  female       university  married  40.0   \n",
       "9    20000.0    male       university  married  27.0   \n",
       "\n",
       "                            PAY_0                           PAY_2  \\\n",
       "0  payment delay for three months  payment delay for three months   \n",
       "1   payment delay for four months  payment delay for three months   \n",
       "2                        pay duly                        pay duly   \n",
       "3     payment delay for one month     payment delay for one month   \n",
       "4                         unknown                         unknown   \n",
       "5  payment delay for three months     payment delay for one month   \n",
       "6     payment delay for one month     payment delay for one month   \n",
       "7     payment delay for one month                        pay duly   \n",
       "8     payment delay for one month     payment delay for one month   \n",
       "9     payment delay for one month     payment delay for one month   \n",
       "\n",
       "                            PAY_3                           PAY_4  \\\n",
       "0     payment delay for one month     payment delay for one month   \n",
       "1  payment delay for three months  payment delay for three months   \n",
       "2                        pay duly                        pay duly   \n",
       "3     payment delay for one month                         unknown   \n",
       "4                         unknown                         unknown   \n",
       "5     payment delay for one month     payment delay for one month   \n",
       "6     payment delay for one month     payment delay for one month   \n",
       "7                        pay duly                        pay duly   \n",
       "8     payment delay for one month     payment delay for one month   \n",
       "9     payment delay for one month   payment delay for four months   \n",
       "\n",
       "                            PAY_5  ... BILL_AMT4  BILL_AMT5  BILL_AMT6  \\\n",
       "0     payment delay for one month  ...   18457.0    21381.0    18914.0   \n",
       "1  payment delay for three months  ...  125357.0   121853.0   124731.0   \n",
       "2                        pay duly  ...    1045.0    12525.0    12219.0   \n",
       "3                         unknown  ...       0.0        0.0        0.0   \n",
       "4                         unknown  ...       0.0     2920.0        0.0   \n",
       "5     payment delay for one month  ...   18055.0    18755.0    20299.0   \n",
       "6     payment delay for one month  ...   17029.0    10575.0     9478.0   \n",
       "7                         unknown  ...    -884.0    -6332.0    -9333.0   \n",
       "8     payment delay for one month  ...  196467.0   201425.0    -8276.0   \n",
       "9  payment delay for three months  ...   18472.0    18037.0    18487.0   \n",
       "\n",
       "   PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "0       0.0    1500.0    1600.0    1646.0     678.0    1000.0   \n",
       "1       0.0    6216.0   10000.0       0.0    5000.0    4552.0   \n",
       "2    1444.0   14019.0    1045.0   12525.0     244.0     725.0   \n",
       "3    2400.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4      35.0       0.0       0.0    2920.0       0.0   12140.0   \n",
       "5    1596.0    1600.0    1300.0    1000.0    2000.0       0.0   \n",
       "6    2500.0    2000.0    2500.0     500.0     500.0     500.0   \n",
       "7    1298.0    6730.0     900.0    5448.0       0.0   25000.0   \n",
       "8    7028.0    6000.0   50000.0   10013.0    9505.0  175074.0   \n",
       "9    3000.0   10000.0       0.0       0.0     900.0    2000.0   \n",
       "\n",
       "   default payment next month  \n",
       "0                           1  \n",
       "1                           1  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "5                           1  \n",
       "6                           0  \n",
       "7                           0  \n",
       "8                           0  \n",
       "9                           0  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{PROCESSED_DATA_DIR}/{DATA_NAME}/train.csv\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "visualize_default(df).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "julian-bumper",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Open the JSON file and read its contents\n",
    "with open(f\"{PROCESSED_DATA_DIR}/{DATA_NAME}/info.json\", \"r\") as file:\n",
    "    data_info = json.load(file)\n",
    "\n",
    "# Display the JSON data\n",
    "# pprint(data_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-factory",
   "metadata": {},
   "source": [
    "# TabDDPM Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daaffdc",
   "metadata": {},
   "source": [
    "In this section, we will describe the design of TabDDPM as well as its main hyperparameters loaded through config, which affect the modelâ€™s effectiveness. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b425e7",
   "metadata": {},
   "source": [
    "**TabDDPM:** uses the multinomial diffusion to model the categorical and binary features, and the Gaussian diffusion to model the numerical ones. The model is trained using the diffusion process, which is a continuous-time Markov chain that models the data distribution. In more detail, for a tabular data sample that consists of N numerical featuresand C categorical features with Ki categories each, TabDDPM takes one-hot encoded versions of categorical features as an input, and normalized numerical features. The figure below illustrates the diffusion process for classification problems; t, y and l denote a diffusion timestep, a class label, and logits, respectively.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"figures/tabddpm.png\" width=\"1000\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37161c0",
   "metadata": {},
   "source": [
    "**Diffusion models:**  are likelihood-based generative models that handle the data through forward and reverse Markov processes. The forward process gradually adds noise to an initial sample x0 from the data distribution q(x0) sampling noise from the predefined distributions q(xt|xtâˆ’1) with variances {Î²1, ..., Î²T}.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"figures/forward.png\" width=\"300\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e6bfff",
   "metadata": {},
   "source": [
    "The reverse diffusion proces gradually denoises a latent variable xTâˆ¼q(xT) and allows generating new data samples from q(x0). Distributions p(xtâˆ’1|xt) are usually unknown and approximated by a neural network with parameters Î¸.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"figures/backward.png\" width=\"280\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c2058",
   "metadata": {},
   "source": [
    "**Gaussian diffusion models:** operate in continuous spaces where forward and reverse processes are characterized by Gaussian distributions:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"figures/gaussian.png\" width=\"440\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad099f5",
   "metadata": {},
   "source": [
    "While in general Î¸ parameters are learned from the data by optimizing a variational lower bound, in practice for Gaussian modeling, this objective can be simplified to the sum of mean-squared errors between ÎµÎ¸(xt ,t) and Îµ over all timesteps t as follows:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"figures/gaussian_loss.png\" width=\"330\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24a46d1",
   "metadata": {},
   "source": [
    "**Multinomial diffusion models:** are designed to generate categorical data where samples are a one-hot encoded categorical variable with K values. The multinomial forward diffusion process defines q(xt|xtâˆ’1) as a categorical distribution that corrupts the data by uniform noise over K classes: \n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"figures/multinomial.png\" width=\"440\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d537779d",
   "metadata": {},
   "source": [
    "The reverse distribution pÎ¸(xtâˆ’1|xt) is parameterized as q(xtâˆ’1|xt,xË†0(xt,t)), where xË†0 is predicted by a neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f362ca1",
   "metadata": {},
   "source": [
    "## Load Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7213754",
   "metadata": {},
   "source": [
    "In this section, we will load the configuration file that contains the hyperparameters for the TabDDPM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a5701a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'device': 'cuda:0',\n",
      " 'diffusion_params': {'gaussian_loss_type': 'mse', 'num_timesteps': 1000},\n",
      " 'eval': {'T': {'cat_encoding': 'one-hot',\n",
      "                'cat_min_frequency': None,\n",
      "                'cat_nan_policy': None,\n",
      "                'normalization': 'quantile',\n",
      "                'num_nan_policy': None,\n",
      "                'seed': 0,\n",
      "                'y_policy': 'default'},\n",
      "          'type': {'eval_model': 'mlp', 'eval_type': 'synthetic'}},\n",
      " 'model_params': {'is_y_cond': False,\n",
      "                  'num_classes': 2,\n",
      "                  'rtdl_params': {'d_layers': [1024, 2048, 2048, 1024],\n",
      "                                  'dropout': 0.0}},\n",
      " 'model_type': 'mlp',\n",
      " 'num_numerical_features': 14,\n",
      " 'sample': {'batch_size': 10000, 'num_samples': 27000, 'seed': 0},\n",
      " 'seed': 0,\n",
      " 'task_type': 'binclass',\n",
      " 'train': {'T': {'cat_encoding': None,\n",
      "                 'cat_min_frequency': None,\n",
      "                 'cat_nan_policy': None,\n",
      "                 'normalization': 'quantile',\n",
      "                 'num_nan_policy': 'mean',\n",
      "                 'seed': 0,\n",
      "                 'y_policy': 'default'},\n",
      "           'main': {'batch_size': 4096,\n",
      "                    'lr': 0.001809824563637657,\n",
      "                    'steps': 100000,\n",
      "                    'weight_decay': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "config_path = f\"src/baselines/tabddpm/configs/{DATA_NAME}.toml\"\n",
    "## Tabddpm is trained unconditional in this repo but conditional in main paper\n",
    "raw_config = src.load_config(config_path)\n",
    "\n",
    "pprint(raw_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871a2bc8",
   "metadata": {},
   "source": [
    "The configuration file is a TOML file that contains the following hyperparameters:\n",
    "\n",
    "1. **model_type:**  specifies the type of backbone model to be used for learning the denoising process. For Adult dataset, this should be set to \"mlp\". The reverse diffusion step in TabDDPM is modelled by a multi-layer neural network that has an output of the same dimensionality as x0, where the first N coordinates are the predictions of Îµ for the Gaussian diffusion and the rest are the predictions of x_ohe for the multinomial diffusions. This model takes as input the corrupted data xt and the timestep t, and outputs the denoised data xtâˆ’1 as follows:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"figures/architecture.png\" width=\"440\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1b8823",
   "metadata": {},
   "source": [
    "2. **model_params:** contains the hyperparameters for the backbone model. For the Adult dataset, we use an MLP model with the following hyperparameters:\n",
    "    - is_y_cond: Whether the model is trained to be conditioned on the target value or not. By default, this should be set to True.\n",
    "    - d_layers: The dimension of layers in the MLP model.\n",
    "    - dropout: The dropout rate.\n",
    "\n",
    "\n",
    "    \n",
    "3. **task_type:** specifice the task type that we will use to conidition our training to and can be binclass (binary classification) or regression, depending on each dataset. For the Adult dataset, the task type is binclass. For classification datasets, we use a class- conditional model, i.e. pÎ¸(xtâˆ’1|xt, y) is learned. For regression datasets, we consider a target value as an additional numerical feature, and the joint distribution is learned.\n",
    "\n",
    "4. **diffusion_params:** contains number of total diffusion steps, the diffusion step size, and type of loss used to minimize the predicited noise in Gaussian diffusion. \n",
    "\n",
    "5. **train.main:** contains the basic hyperparameters for training the model such number of epochs (steps), the batch size (batch_size), the learning rate(lr), and the rate of weight decay (weight_decay).\n",
    "\n",
    "6. **train.T:** contains the defined transformations on train data such as normalization, standardization, and one-hot encoding. \n",
    "    - For preprocessing numerical features, we use the gaussian quantile transformation and replace the Nan values with mean of each row. \n",
    "    - For categorical features, we use the one-hot encoding method. Each categorical feature is handled by a separate forward diffusion process, i.e., the noise components for all features are sampled independently. \n",
    "\n",
    "7. **sample:** contains the hyperparameters for sampling the data from the trained model. It includes the number of samples to generate, the batch size of sampling, and the seed used for random noise initialization.\n",
    "\n",
    "8. **eval.T:** contains the defined transformations on evaluation data such as normalization, standardization, and one-hot encoding. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-quality",
   "metadata": {},
   "source": [
    "## Make Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b6854c",
   "metadata": {},
   "source": [
    "Now that we have processed the data, we can create a dataset object. First we instantiate transformations needed for the dataset, such as normalization, standardization, and one-hot encoding in `T`. Next using make_dataset function we create a dataset object that contains the training and test data, as well as the column names, numerical column indices, and categorical column indices. This function takes the directory containing the processed data, the transformation and task type as input. Also it takes a boolean argument `change_val` that if it set true it will change the validation data to a split of train data rather than test data.\n",
    "It returns a dataset object that contains the training and test data, as well as the column names, numerical column indices, and categorical column indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "second-romance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaNs in numerical features, skipping\n"
     ]
    }
   ],
   "source": [
    "T = src.Transformations(**raw_config[\"train\"][\"T\"])\n",
    "\n",
    "dataset = make_dataset(\n",
    "    f\"{PROCESSED_DATA_DIR}/{DATA_NAME}\",\n",
    "    T,\n",
    "    task_type=raw_config[\"task_type\"],\n",
    "    change_val=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2b294c",
   "metadata": {},
   "source": [
    "## Instantiate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984a84c6",
   "metadata": {},
   "source": [
    "Next, we instantiate the TabDDPM model. To do so first we need to apply some modifactions to loaded configs based on the dataset. We will set the number of numerical and size of one-hot coded categorical features based on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "allied-sunday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each Categorical Features Size:  [ 2  2  7  4 11 11 11 11 10 10]\n",
      "Numerical Features Size:  14\n"
     ]
    }
   ],
   "source": [
    "dim_categorical_features = np.array(dataset.get_category_sizes(\"train\"))\n",
    "print(\"Each Categorical Features Size: \",dim_categorical_features)\n",
    "if (\n",
    "    len(dim_categorical_features) == 0\n",
    "    or raw_config[\"train\"][\"T\"][\"cat_encoding\"] == \"one-hot\"\n",
    "):\n",
    "    dim_categorical_features = np.array([0])\n",
    "\n",
    "num_numerical_features = (\n",
    "    dataset.X_num[\"train\"].shape[1] if dataset.X_num is not None else 0\n",
    ")\n",
    "print(\"Numerical Features Size: \",num_numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59532a94",
   "metadata": {},
   "source": [
    "We will also set the input size of the model as sum of size of categorical plus length of numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c2fb00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Input Size: 93\n"
     ]
    }
   ],
   "source": [
    "dim_input = np.sum(dim_categorical_features) + num_numerical_features\n",
    "raw_config[\"model_params\"][\"d_in\"] = dim_input\n",
    "print(\"Model Input Size:\", dim_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a14719",
   "metadata": {},
   "source": [
    "Also we set device to be \"cuda\" if available otherwise we will use \"cpu\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f47437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3661314c",
   "metadata": {},
   "source": [
    "Finally, we will instantiate the model using the `TabDDPM` class. TabDDPM class takes the following arguments:\n",
    "\n",
    "1. dataset: The dataset object containing the training and test data, as well as the column names, numerical column indices, and categorical column indices.\n",
    "2. num_numerical_features: The number of numerical features in the dataset.\n",
    "3. dim_categorical_features: The list of size of the one-hot encoded categorical features.\n",
    "4. model_type: The type of backbone model to be used for learning the denoising process.\n",
    "5. model_params: The hyperparameters for the backbone model.\n",
    "6. diffusion_params: The hyperparameters for the diffusion process.\n",
    "7. device: The device to use for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "developed-gross",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_classes': 2, 'is_y_cond': False, 'rtdl_params': {'d_layers': [1024, 2048, 2048, 1024], 'dropout': 0.0}, 'd_in': 93}\n",
      "the number of parameters 11734109\n"
     ]
    }
   ],
   "source": [
    "tabddpm = TabDDPM(\n",
    "    dataset=dataset,\n",
    "    num_numerical_features=num_numerical_features,\n",
    "    num_classes=dim_categorical_features,\n",
    "    model_type=raw_config[\"model_type\"],\n",
    "    model_params=raw_config[\"model_params\"],\n",
    "    device=device,\n",
    "    **raw_config[\"diffusion_params\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38efa0e",
   "metadata": {},
   "source": [
    "TabDDPM class first instantiates the backbone model, which is a multi-layer neural network that models the reverse diffusion process using `get_model` function. It then passes this model to `GaussianMultinomialDiffusion` class to initializes the diffusion process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-boost",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f204dce9",
   "metadata": {},
   "source": [
    "Now that we have instantiated the model, we can train it using the `train` function. This function takes the training arguments from the config file and path to save the trained model. It trains the model on the training data using the `Trainer` class. It returns the trained model and the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-jimmy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "os.makedirs(f\"{MODEL_PATH}/{DATA_NAME}\")\n",
    "\n",
    "tabddpm.train(\n",
    "    **raw_config[\"train\"][\"main\"],\n",
    "    model_save_path=f\"{MODEL_PATH}/{DATA_NAME}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0624de8",
   "metadata": {},
   "source": [
    "## Load pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9def4df",
   "metadata": {},
   "source": [
    "Instead of training model from scratch, we can also load weights of pre-trained model from give checkpoint with `load_model` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29eb097c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /projects/diffusion_bootcamp/models/tabular/tabddpm/default/model_100000.pt\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_path = \"/projects/diffusion_bootcamp/models/tabular/tabddpm/default/model_100000.pt\"\n",
    "\n",
    "tabddpm.load_model(\n",
    "    ckpt_path=pretrained_model_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-smile",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6801c3",
   "metadata": {},
   "source": [
    "Now that we trained the model effectively, using `sample` function we can generate synthetic data starting from compelete noise. The input of this function is as follows:\n",
    "\n",
    "1. info_path: The path to the JSON file containing the information about the dataset.\n",
    "2. num_samples: The number of samples to generate.\n",
    "3. batch_size: The batch size for sampling the data.\n",
    "4. sample_save_path: The path to save the generated samples.\n",
    "5. ddim: Whether the sampling strategy is DDPM (Denoising Diffusion Probabilistic Models) and DDIM (Denoising Diffusion Implicit Models). DDPM produces high-quality samples but requires many computationally expensive sampling steps, making it slower. In contrast, DDIM (Denoising Diffusion Implicit Models) offers faster sampling with fewer steps by using a deterministic process, maintaining similar sample quality with improved efficiency. The choice between them depends on the need for speed versus the highest possible sample quality.\n",
    "6. steps: The number of steps for sampling the data. This is the number of diffusion steps to take when sampling the data. The higher the number of steps, the better the quality of the generated samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stainless-ferry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample using DDIM.\n",
      "Sample timestep  999\n",
      "Sample timestep  999\n",
      "Sample timestep  999\n",
      "(27000, 10)\n",
      "Sampling time: 174.21547436714172\n"
     ]
    }
   ],
   "source": [
    "tabddpm.sample(\n",
    "    info_path=f\"{PROCESSED_DATA_DIR}/{DATA_NAME}/info.json\",\n",
    "    num_samples=raw_config[\"sample\"][\"num_samples\"],\n",
    "    batch_size=raw_config[\"sample\"][\"batch_size\"],\n",
    "    sample_save_path=f\"{SYNTH_DATA_DIR}/{DATA_NAME}/tabddpm.csv\",\n",
    "    ddim=True,\n",
    "    steps=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-encounter",
   "metadata": {},
   "source": [
    "## Review Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb748981",
   "metadata": {},
   "source": [
    "Finally here, we review the synthesized data. In the following `evaluate_synthetic_data.ipynb` notebook, we will evaluate this synthesized data with respect to various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "constitutional-price",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>female</td>\n",
       "      <td>high school</td>\n",
       "      <td>single</td>\n",
       "      <td>49.0</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>...</td>\n",
       "      <td>9028.37800</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2000.00000</td>\n",
       "      <td>2074.8210</td>\n",
       "      <td>5317.57500</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>married</td>\n",
       "      <td>32.0</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>...</td>\n",
       "      <td>16427.72500</td>\n",
       "      <td>-4363.7830</td>\n",
       "      <td>12100.33300</td>\n",
       "      <td>3518.13450</td>\n",
       "      <td>2500.0000</td>\n",
       "      <td>1867.56840</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>17095.41600</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>single</td>\n",
       "      <td>35.0</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>...</td>\n",
       "      <td>11077.29000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7858.3213</td>\n",
       "      <td>11506.51000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>female</td>\n",
       "      <td>graduate school</td>\n",
       "      <td>single</td>\n",
       "      <td>24.0</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>...</td>\n",
       "      <td>19580.71500</td>\n",
       "      <td>14270.3440</td>\n",
       "      <td>12035.43800</td>\n",
       "      <td>2000.00000</td>\n",
       "      <td>2000.0000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>386.86182</td>\n",
       "      <td>329.12270</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>single</td>\n",
       "      <td>26.0</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>...</td>\n",
       "      <td>84337.36000</td>\n",
       "      <td>93378.7100</td>\n",
       "      <td>89728.94500</td>\n",
       "      <td>4000.00000</td>\n",
       "      <td>3978.4920</td>\n",
       "      <td>2201.65400</td>\n",
       "      <td>3100.78960</td>\n",
       "      <td>2020.78750</td>\n",
       "      <td>3353.50830</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>260000.0</td>\n",
       "      <td>female</td>\n",
       "      <td>graduate school</td>\n",
       "      <td>single</td>\n",
       "      <td>37.0</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>...</td>\n",
       "      <td>1519.36060</td>\n",
       "      <td>595.3594</td>\n",
       "      <td>832.78204</td>\n",
       "      <td>1200.00000</td>\n",
       "      <td>3689.1450</td>\n",
       "      <td>2000.00000</td>\n",
       "      <td>659.12390</td>\n",
       "      <td>713.51465</td>\n",
       "      <td>955.44214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>male</td>\n",
       "      <td>high school</td>\n",
       "      <td>married</td>\n",
       "      <td>50.0</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>324.77527</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>male</td>\n",
       "      <td>high school</td>\n",
       "      <td>married</td>\n",
       "      <td>41.0</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>...</td>\n",
       "      <td>23512.64500</td>\n",
       "      <td>15033.1480</td>\n",
       "      <td>15429.45600</td>\n",
       "      <td>1600.00000</td>\n",
       "      <td>1721.2130</td>\n",
       "      <td>1006.85156</td>\n",
       "      <td>700.00000</td>\n",
       "      <td>537.01526</td>\n",
       "      <td>523.36816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>418339.1</td>\n",
       "      <td>female</td>\n",
       "      <td>graduate school</td>\n",
       "      <td>married</td>\n",
       "      <td>43.0</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.49854</td>\n",
       "      <td>2236.4229</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>18998.07600</td>\n",
       "      <td>2406.0164</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7000.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>547.17230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>130000.0</td>\n",
       "      <td>male</td>\n",
       "      <td>graduate school</td>\n",
       "      <td>married</td>\n",
       "      <td>34.0</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>payment delay for one month</td>\n",
       "      <td>...</td>\n",
       "      <td>103908.62500</td>\n",
       "      <td>79585.3750</td>\n",
       "      <td>81162.31000</td>\n",
       "      <td>3500.00000</td>\n",
       "      <td>3648.4895</td>\n",
       "      <td>3610.25150</td>\n",
       "      <td>3000.00000</td>\n",
       "      <td>3000.00000</td>\n",
       "      <td>2888.82860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL     SEX        EDUCATION MARRIAGE   AGE  \\\n",
       "0   160000.0  female      high school   single  49.0   \n",
       "1   100000.0  female       university  married  32.0   \n",
       "2   150000.0  female       university   single  35.0   \n",
       "3    50000.0  female  graduate school   single  24.0   \n",
       "4    70000.0  female       university   single  26.0   \n",
       "5   260000.0  female  graduate school   single  37.0   \n",
       "6    30000.0    male      high school  married  50.0   \n",
       "7    30000.0    male      high school  married  41.0   \n",
       "8   418339.1  female  graduate school  married  43.0   \n",
       "9   130000.0    male  graduate school  married  34.0   \n",
       "\n",
       "                         PAY_0                        PAY_2  \\\n",
       "0  payment delay for one month  payment delay for one month   \n",
       "1  payment delay for one month  payment delay for one month   \n",
       "2                     pay duly                     pay duly   \n",
       "3  payment delay for one month  payment delay for one month   \n",
       "4  payment delay for one month  payment delay for one month   \n",
       "5                     pay duly                     pay duly   \n",
       "6  payment delay for one month  payment delay for one month   \n",
       "7  payment delay for one month  payment delay for one month   \n",
       "8                     pay duly                     pay duly   \n",
       "9  payment delay for one month  payment delay for one month   \n",
       "\n",
       "                         PAY_3                        PAY_4  \\\n",
       "0                     pay duly                     pay duly   \n",
       "1                     pay duly  payment delay for one month   \n",
       "2                     pay duly                     pay duly   \n",
       "3  payment delay for one month  payment delay for one month   \n",
       "4  payment delay for one month  payment delay for one month   \n",
       "5                     pay duly                     pay duly   \n",
       "6  payment delay for one month                      unknown   \n",
       "7  payment delay for one month  payment delay for one month   \n",
       "8                     pay duly                     pay duly   \n",
       "9  payment delay for one month  payment delay for one month   \n",
       "\n",
       "                         PAY_5  ...     BILL_AMT4   BILL_AMT5    BILL_AMT6  \\\n",
       "0                     pay duly  ...    9028.37800      0.0000      0.00000   \n",
       "1  payment delay for one month  ...   16427.72500  -4363.7830  12100.33300   \n",
       "2                     pay duly  ...   11077.29000      0.0000      0.00000   \n",
       "3  payment delay for one month  ...   19580.71500  14270.3440  12035.43800   \n",
       "4  payment delay for one month  ...   84337.36000  93378.7100  89728.94500   \n",
       "5                     pay duly  ...    1519.36060    595.3594    832.78204   \n",
       "6                      unknown  ...       0.00000      0.0000      0.00000   \n",
       "7  payment delay for one month  ...   23512.64500  15033.1480  15429.45600   \n",
       "8                     pay duly  ...    -100.49854   2236.4229      0.00000   \n",
       "9  payment delay for one month  ...  103908.62500  79585.3750  81162.31000   \n",
       "\n",
       "      PAY_AMT1   PAY_AMT2     PAY_AMT3    PAY_AMT4     PAY_AMT5    PAY_AMT6  \\\n",
       "0   2000.00000  2074.8210   5317.57500     0.00000      0.00000     0.00000   \n",
       "1   3518.13450  2500.0000   1867.56840     0.00000  17095.41600  1500.00000   \n",
       "2      0.00000  7858.3213  11506.51000     0.00000      0.00000     0.00000   \n",
       "3   2000.00000  2000.0000   1000.00000   386.86182    329.12270   500.00000   \n",
       "4   4000.00000  3978.4920   2201.65400  3100.78960   2020.78750  3353.50830   \n",
       "5   1200.00000  3689.1450   2000.00000   659.12390    713.51465   955.44214   \n",
       "6    324.77527     0.0000      0.00000     0.00000      0.00000     0.00000   \n",
       "7   1600.00000  1721.2130   1006.85156   700.00000    537.01526   523.36816   \n",
       "8  18998.07600  2406.0164      0.00000  7000.00000      0.00000   547.17230   \n",
       "9   3500.00000  3648.4895   3610.25150  3000.00000   3000.00000  2888.82860   \n",
       "\n",
       "   default payment next month  \n",
       "0                           1  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           1  \n",
       "4                           1  \n",
       "5                           1  \n",
       "6                           0  \n",
       "7                           0  \n",
       "8                           0  \n",
       "9                           0  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{SYNTH_DATA_DIR}/{DATA_NAME}/tabddpm.csv\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "visualize_default(df).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e82ee8",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b905aa",
   "metadata": {},
   "source": [
    "**Kotelnikov, Akim, et al.** \"TABDDPM: Modeling tabular data with diffusion models.\" *Advances in Neural Information Processing Systems* 36 (2021).\n",
    "\n",
    "**GitHub Repository:** [Amazon Science - Tabsyn](https://github.com/amazon-science/tabsyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-sandwich",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_models_show",
   "language": "python",
   "name": "diffusion_models_show"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
